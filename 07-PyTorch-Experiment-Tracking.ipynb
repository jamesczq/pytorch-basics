{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f0de920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment tracking helps you figure out what works and what doesn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e3f8555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different ways to to track ML experiments:\n",
    "\n",
    "# Simple print-out, say save experiment results in CSV\n",
    "\n",
    "# TensorBoard\n",
    "\n",
    "# MLFlow\n",
    "# Full MLOps lifecycle management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478e8c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook focuses on using TensorBoard to track experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44294ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] torch/torchvision versions not as required, installing nightly versions.\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch in c:\\users\\james\\anaconda3\\envs\\torch\\lib\\site-packages (2.0.0+cu117)\n",
      "Requirement already satisfied: torchvision in c:\\users\\james\\anaconda3\\envs\\torch\\lib\\site-packages (0.15.1+cu117)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\james\\anaconda3\\envs\\torch\\lib\\site-packages (2.0.1+cu117)\n",
      "Requirement already satisfied: networkx in c:\\users\\james\\anaconda3\\envs\\torch\\lib\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\james\\anaconda3\\envs\\torch\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\james\\anaconda3\\envs\\torch\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\james\\anaconda3\\envs\\torch\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\james\\anaconda3\\envs\\torch\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\james\\anaconda3\\envs\\torch\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\james\\anaconda3\\envs\\torch\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\james\\anaconda3\\envs\\torch\\lib\\site-packages (from torchvision) (1.24.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\james\\anaconda3\\envs\\torch\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\james\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\james\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\james\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\james\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\james\\anaconda3\\envs\\torch\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "torch version: 2.0.0+cu117\n",
      "torchvision version: 0.15.1+cu117\n"
     ]
    }
   ],
   "source": [
    "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
    "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "except:\n",
    "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
    "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b245dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src_05_modular import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "077731dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = utils.get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7b551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b01a33ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('data/pizza_steak_sushi')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = pathlib.Path(\"data/\")/\"pizza_steak_sushi\"\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da52fc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('data/pizza_steak_sushi/train'),\n",
       " WindowsPath('data/pizza_steak_sushi/test'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = image_path/\"train\"\n",
    "test_dir = image_path/\"test\"\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e0b2c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "804b4749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[256]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BICUBIC\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automatic_transforms = weights.transforms()\n",
    "automatic_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e29c3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src_05_modular import data_setup, engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bf73662",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=automatic_transforms,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1568c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pre-trained model (freeze base layers; change the classifier head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f144411",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.efficientnet_b0(weights=weights)\n",
    "\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True),\n",
    "    torch.nn.Linear(in_features=1280, out_features=len(class_names), bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "839ccb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa31ae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\anaconda3\\envs\\torch\\lib\\site-packages\\torchinfo\\torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "C:\\Users\\james\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 3]              --                   Partial\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   False\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   (864)                False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   (64)                 False\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   (1,448)              False\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     (6,004)              False\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     (10,710)             False\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 40, 28, 28]     (15,350)             False\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28]     [32, 40, 28, 28]     (31,290)             False\n",
       "│    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28]     [32, 80, 14, 14]     (37,130)             False\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14]     [32, 112, 14, 14]    (126,004)            False\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14]    [32, 192, 7, 7]      (262,492)            False\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7]      [32, 320, 7, 7]      (717,232)            False\n",
       "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 320, 7, 7]      [32, 1280, 7, 7]     (409,600)            False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     [32, 1280, 7, 7]     (2,560)              False\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1280]           [32, 3]              --                   True\n",
       "│    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1280]           [32, 3]              3,843                True\n",
       "============================================================================================================================================\n",
       "Total params: 4,011,391\n",
       "Trainable params: 3,843\n",
       "Non-trainable params: 4,007,548\n",
       "Total mult-adds (G): 12.31\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.09\n",
       "Params size (MB): 16.05\n",
       "Estimated Total Size (MB): 3487.41\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(\n",
    "    model, \n",
    "    input_size=(32, 3, 224, 224), # (batch_size, color_channels, height, width)\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ac7d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdc913dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c383869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9117da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3455f9",
   "metadata": {},
   "source": [
    "## Track results using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d61ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tensorboard.SummaryWriter() class to save various parts of model training progress\n",
    "\n",
    "# Be default, SummaryWriter() saves info to a file defined by the log_dir parameter,\n",
    "# and the default location of log_dir is runs/CURRENT_DATETIME_HOSTNAME.\n",
    "# Note: the TensorBoard format is part of TensorFlow library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "443e272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02da2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0725ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_check_caffe2_blob',\n",
       " '_encode',\n",
       " '_get_file_writer',\n",
       " 'add_audio',\n",
       " 'add_custom_scalars',\n",
       " 'add_custom_scalars_marginchart',\n",
       " 'add_custom_scalars_multilinechart',\n",
       " 'add_embedding',\n",
       " 'add_figure',\n",
       " 'add_graph',\n",
       " 'add_histogram',\n",
       " 'add_histogram_raw',\n",
       " 'add_hparams',\n",
       " 'add_image',\n",
       " 'add_image_with_boxes',\n",
       " 'add_images',\n",
       " 'add_mesh',\n",
       " 'add_onnx_graph',\n",
       " 'add_pr_curve',\n",
       " 'add_pr_curve_raw',\n",
       " 'add_scalar',\n",
       " 'add_scalars',\n",
       " 'add_text',\n",
       " 'add_video',\n",
       " 'all_writers',\n",
       " 'close',\n",
       " 'default_bins',\n",
       " 'file_writer',\n",
       " 'filename_suffix',\n",
       " 'flush',\n",
       " 'flush_secs',\n",
       " 'get_logdir',\n",
       " 'log_dir',\n",
       " 'max_queue',\n",
       " 'purge_step']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "483bf240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to modify the src_05_modular.engine.train() function to \n",
    "# log model's training and test accuracies and losses, using\n",
    "# writer.add_scalars(\n",
    "# main_tag: str=\"Loss\", \n",
    "# tag_scalar_dict: dict={\"train_loss\":train_loss, \"test_loss\":test_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aef9575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For changes, see src_07_exp_tracking.engine.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56ebca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model: torch.nn.Module, \n",
    "#           train_dataloader: torch.utils.data.DataLoader, \n",
    "#           test_dataloader: torch.utils.data.DataLoader, \n",
    "#           optimizer: torch.optim.Optimizer,\n",
    "#           loss_fn: torch.nn.Module,\n",
    "#           epochs: int,\n",
    "#           device: torch.device) -> Dict[str, List]:\n",
    "\n",
    "#    Omit ...\n",
    "\n",
    "#         # Update results dictionary\n",
    "#         results[\"train_loss\"].append(train_loss)\n",
    "#         results[\"train_acc\"].append(train_acc)\n",
    "#         results[\"test_loss\"].append(test_loss)\n",
    "#         results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "# NEW:\n",
    "\n",
    "\n",
    "#         ### New: Experiment tracking ###\n",
    "#         # Add loss results to SummaryWriter\n",
    "#         writer.add_scalars(main_tag=\"Loss\", \n",
    "#                            tag_scalar_dict={\"train_loss\": train_loss,\n",
    "#                                             \"test_loss\": test_loss},\n",
    "#                            global_step=epoch)\n",
    "\n",
    "#         # Add accuracy results to SummaryWriter\n",
    "#         writer.add_scalars(main_tag=\"Accuracy\", \n",
    "#                            tag_scalar_dict={\"train_acc\": train_acc,\n",
    "#                                             \"test_acc\": test_acc}, \n",
    "#                            global_step=epoch)\n",
    "        \n",
    "#         # Track the PyTorch model architecture\n",
    "#         writer.add_graph(model=model, \n",
    "#                          # Pass in an example input\n",
    "#                          input_to_model=torch.randn(32, 3, 224, 224).to(device))\n",
    "    \n",
    "#     # Close the writer\n",
    "#     writer.close()\n",
    "    \n",
    "#     ### End new ###\n",
    "\n",
    "#     # Return the filled results at the end of the epochs\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9079f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src_07_exp_tracking import engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c33186d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad097f3ebfb94658ade3088554770a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss: 1.0581, Train acc: 0.4635 |  Test loss: 0.9669, Test acc: 0.6165\n",
      "Epoch 2: Train loss: 0.9331, Train acc: 0.6352 |  Test loss: 0.7968, Test acc: 0.7685\n",
      "Epoch 3: Train loss: 0.7905, Train acc: 0.7753 |  Test loss: 0.7218, Test acc: 0.8764\n",
      "Epoch 4: Train loss: 0.6901, Train acc: 0.8332 |  Test loss: 0.6576, Test acc: 0.9233\n",
      "Epoch 5: Train loss: 0.6254, Train acc: 0.8606 |  Test loss: 0.5687, Test acc: 0.9531\n",
      "\n",
      ">>>Tensorboard logs saved in runs\\Mar28_22-30-30_LAPTOP-NU5KNMS8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = engine.train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=5,\n",
    "    device=device,\n",
    "    writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c00f8488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [1.0581388622522354,\n",
       "  0.9331417083740234,\n",
       "  0.7905052900314331,\n",
       "  0.6900958269834518,\n",
       "  0.6254110038280487],\n",
       " 'train_acc': [0.46354166666666663,\n",
       "  0.6351799242424243,\n",
       "  0.7753314393939394,\n",
       "  0.8332149621212122,\n",
       "  0.8605587121212122],\n",
       " 'test_loss': [0.966871589422226,\n",
       "  0.7968323826789856,\n",
       "  0.7218093574047089,\n",
       "  0.6575829982757568,\n",
       "  0.5686689615249634],\n",
       " 'test_acc': [0.6164772727272727,\n",
       "  0.7684659090909092,\n",
       "  0.8764204545454546,\n",
       "  0.9232954545454546,\n",
       "  0.953125]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08114161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7696), started 0:43:55 ago. (Use '!kill 7696' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-57ef90d25aa1431d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-57ef90d25aa1431d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aaf36d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a helper function to define usage of SummaryWriter() \n",
    "# such that each experiment gets its own log directory with names like\n",
    "# Experiment timestamp\n",
    "# Experiment name\n",
    "# Experiment model's name\n",
    "# Anything extra\n",
    "# Example:\n",
    "# runs/YYYY-MM-DD/exp_name/model_name/extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbf0360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8037d400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-03-28'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "261d89f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See its details in src_07_exp_tracking\n",
    "def create_writer(\n",
    "    experiment_name:str, \n",
    "    model_name:str, \n",
    "    extra:str=None\n",
    ") -> torch.utils.tensorboard.writer.SummaryWriter():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce3b7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6faf043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src_07_exp_tracking import engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26b9e0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src_07_exp_tracking.engine' from 'C:\\\\Users\\\\james\\\\repos\\\\pytorch-basics\\\\src_07_exp_tracking\\\\engine.py'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c867bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try various experiments\n",
    "# * Change num of epochs\n",
    "# * Change num of layers/hidden units\n",
    "# * Change amount of data\n",
    "# * Change learning rate\n",
    "# * Try diff kinds of data augmentation\n",
    "# * Choose diff model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "28906e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the following, we'll try the following combinations:\n",
    "# 1. Diff amount of data (10% of Pizza/Steak/Sushi vs 20%)\n",
    "# 2. Diff models (efficientnet_b0 vs efficientnet_b2)\n",
    "# 3. Diff training time (5 vs 10 epochs)\n",
    "# So that's 2*2*2 = 8 experiments to track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e53c94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data: 10% vs 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b73c3125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "def download_data(source: str, \n",
    "                  destination: str,\n",
    "                  remove_source: bool = True) -> Path:\n",
    "    \"\"\"Downloads a zipped dataset from source and unzips to destination.\n",
    "\n",
    "    Args:\n",
    "        source (str): A link to a zipped file containing data.\n",
    "        destination (str): A target directory to unzip data to.\n",
    "        remove_source (bool): Whether to remove the source after downloading and extracting.\n",
    "    \n",
    "    Returns:\n",
    "        pathlib.Path to downloaded data.\n",
    "    \n",
    "    Example usage:\n",
    "        download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "                      destination=\"pizza_steak_sushi\")\n",
    "    \"\"\"\n",
    "    # Setup path to data folder\n",
    "    data_path = Path(\"data/\")\n",
    "    image_path = data_path / destination\n",
    "\n",
    "    # If the image folder doesn't exist, download it and prepare it... \n",
    "    if image_path.is_dir():\n",
    "        print(f\"[INFO] {image_path} directory exists, skipping download.\")\n",
    "    else:\n",
    "        print(f\"[INFO] Did not find {image_path} directory, creating one...\")\n",
    "        image_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Download pizza, steak, sushi data\n",
    "        target_file = Path(source).name\n",
    "        with open(data_path / target_file, \"wb\") as f:\n",
    "            request = requests.get(source)\n",
    "            print(f\"[INFO] Downloading {target_file} from {source}...\")\n",
    "            f.write(request.content)\n",
    "\n",
    "        # Unzip pizza, steak, sushi data\n",
    "        with zipfile.ZipFile(data_path / target_file, \"r\") as zip_ref:\n",
    "            print(f\"[INFO] Unzipping {target_file} data...\") \n",
    "            zip_ref.extractall(image_path)\n",
    "\n",
    "        # Remove .zip file\n",
    "        if remove_source:\n",
    "            os.remove(data_path / target_file)\n",
    "    \n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "df988b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data\\pizza_steak_sushi directory exists, skipping download.\n",
      "[INFO] Did not find data\\pizza_steak_sushi_20_percent directory, creating one...\n",
      "[INFO] Downloading pizza_steak_sushi_20_percent.zip from https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip...\n",
      "[INFO] Unzipping pizza_steak_sushi_20_percent.zip data...\n"
     ]
    }
   ],
   "source": [
    "# Download 10 percent and 20 percent training data (if necessary)\n",
    "data_10_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "                                     destination=\"pizza_steak_sushi\")\n",
    "\n",
    "data_20_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\",\n",
    "                                     destination=\"pizza_steak_sushi_20_percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bcc788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d57d2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fbfd26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3e0300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e095b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8bcb83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bca2794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b60c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfafda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa0af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caca08d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a6451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2ab4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b48b11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d4177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b52e4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a220143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5c4ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc560b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe3239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e00ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bac4193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c218259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
